<!DOCTYPE HTML>

<html lang="en">
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="description" content="Shifu" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Wisconsin Diagnostic Breast Cancer Tutorial</title>
  <script src="http://code.jquery.com/jquery-latest.js" type="text/javascript">
</script>
  <link rel="stylesheet" href="//netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css" type="text/css">
  <script src="//netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js" type="text/javascript">
</script>
  <script src="/javascripts/main.js" type="text/javascript">
</script>
  <link rel="stylesheet" href="/coderay.css" type="text/css">
  <link rel="stylesheet" href="/style.css" type="text/css">
  <link rel="icon" href="/images/owl_head_32.png">
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>

  <body>
	
	<header id="header" role="banner">
		<nav class="navbar navbar-default" role="navigation">
			<div class="navbar-header">
			  <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar-collapse">
				<span class="sr-only">Toggle navigation</span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
			  </button>
			  <a href="http://paypal.github.io" class="navbar-brand"><img src="/images/OSSLogoPP.png" alt="PayPal open source" /></a>
			</div>
			<div class="collapse navbar-collapse" id="navbar-collapse">
				<ul class="nav navbar-nav">
					<li><a href="/" id="shifu-logo"><img src="/images/shifu-logo.png" height="44" ></a>



					<!--<li><a href="/project/about">About</a></li>-->

          <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown">Project<b class="caret"></b></a>
            <ul class="dropdown-menu">
              <li><a href="/project/about">About</a></li>
              <li><a href="/project/how-to-contribute">How to Contribute</a></li>
              
            </ul>
          </li>

					<li class="dropdown">
						<a href="#" class="dropdown-toggle" data-toggle="dropdown">Getting Started<b class="caret"></b></a>
						<ul class="dropdown-menu">
							<li><a href="/project/download">Download</a></li>
							<li><a href="/docs/shifu-core/0.2.x/tutorials/quickstart">Quick Start</a></li>

						</ul>
					</li>
					<li class="dropdown">
						<a href="#" class="dropdown-toggle" data-toggle="dropdown">Documentation<b class="caret"></b></a>
						<ul class="dropdown-menu">
							<li><a href="/docs/shifu-core/0.2.x">Shifu-Core</a></li>
							<li><a href="/docs/guagua">Guagua</a></li>
						</ul>
					</li>
					
				</ul>
			</div>
		</nav>
	</header>
 
  

  <div class="container" id="content">
    <div class="row">
      <div class="col-md-9">
        <div id="main">
          
<h1 id="wisconsin-diagnostic-breast-cancer-tutorial">Wisconsin Diagnostic Breast Cancer Tutorial</h1>

<p>This tutorial trains a model on the <a href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)">Wisconsin Diagnostic Breast Cancer</a> data set.  The models tries to predict a diagnosis of <strong>Benign</strong> or <strong>Malignant</strong>.</p>

<p>Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.</p>

<h2 id="prerequisites">Prerequisites</h2>

<p><a href="/project/download/#download">Download</a> and <a href="/project/download/#install">install</a> Shifu onto your machine with direct Hadoop and HDFS access.  For this tutorial, we’ll refer to this machine as you Hadoop CLI machine, <code>hadoopcli</code>.</p>

<p>In order to run Shifu on Hadoop, ensure that your Hadoop CLI machine has <a href="http://pig.apache.org/">Pig</a> installed.</p>

<pre><code>hadoopcli:~$ which pig
/usr/local/bin/pig
</code></pre>

<p>In order to train a model on Hadoop, ensure that your Hadoop cluster has a running <a href="http://zookeeper.apache.org/">ZooKeeper</a> installation. </p>

<p>For this tutoral, let’s assume the ZooKeeper hosts are <code>zookeeper1, zookeeper2, zookeeper3</code>.  Shifu needs to be configured to use those ZooKeeper hosts by modifying  <code>$SHIFU_HOME/conf/shifuconfig</code> like so:</p>

<pre><code># zookeeperServers is used for distributed training 
zookeeperServers=zookeeper1,zookeeper2,zookeeper3
</code></pre>

<h2 id="prepare-the-training-data">Prepare the training data</h2>

<p>Create a new folder <code>wdbcDataSet</code> to store the training data:</p>

<pre><code>hadoopcli:~$ mkdir wdbcDataSet
hadoopcli:~$ cd wdbcDataSet
</code></pre>

<p>Download the data:</p>

<pre><code>hadoopcli:wdbcDataSet$ wget http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data
</code></pre>

<p>Split the data into 2 parts: training and evaluation:</p>

<pre><code>hadoopcli:wdbcDataSet$ awk '{s=rand(); if(s&gt;0.2){print &gt; "wdbc.train"}else{print &gt; "wdbc.eval"}}' wdbc.data
</code></pre>

<p>Create a new file called <code>wdbc.header</code> with the following data:</p>

<pre><code>id|diagnosis|mean_radius|mean_texture|mean_perimeter|mean_area|mean_smoothness|mean_compactness|mean_concavity|mean_concave_points|mean_symmetry|mean_fractal_dimension|std_radius|std_texture|std_perimeter|std_area|std_smoothness|std_compactness|std_concavity|std_concave_points|std_symmetry|std_fractal_dimension|worst_radius|worst_texture|worst_perimeter|worst_area|worst_smoothness|worst_compactness|worst_concavity|worst_concave_points|worst_symmetry|worst_fractal_dimension
</code></pre>

<p>The final folder layout of <code>wdbcDataSet</code> should be:</p>

<pre><code>wdbcDataSet/
├───wdbc.data
├───wdbc.train
├───wdbc.eval
└───wdbc.header
</code></pre>

<p>Put <code>wdbcDataSet</code> onto HDFS:</p>

<pre><code>hadoopcli:wdbcDataSet$ cd ..
hadoopcli:~/$ hadoop fs -put wdbcDataSet wdbcDataSet
</code></pre>

<h2 id="create-initial-modelconfig">Create Initial ModelConfig</h2>

<p>Now that the training set is created and put on to HDFS, create a new Shifu ModelSet:</p>

<pre><code>hadoopcli:~/$ shifu new wdbcModel
hadoopcli:~/$ cd wdbcModel
</code></pre>

<h2 id="choose-the-runmode">Choose the RunMode</h2>

<p>Shifu can run either locally on the Hadoop CLI machine or on Hadoop.  By default, Shifu will run locally.  To configure Shifu to run on Hadoop, open <code>ModelConfig.json</code> and make the following change:</p>

<pre><code>"runMode" : "mapred",
</code></pre>

<h2 id="create-initial-columnconfig">Create Initial ColumnConfig</h2>

<p>Now it’s time to configure Shifu to use the WDBC data set on HDFS.</p>

<p>First, we need to let Shifu know to not use the column <code>id</code> as a variable.   Open <code>meta.column.names</code> and add the follow line:</p>

<pre><code>id
</code></pre>

<p>Next, open <code>ModelConfig.json</code> and make the following changes to the <code>dataSet</code> section to configure Shifu to use the WDBC data set on HDFS: </p>

<pre><code>"dataSet" : {
	"source" : "HDFS",
	"dataPath" : "/wdbcDataSet/wdbc.train",
	"dataDelimiter" : ",",
	"headerPath" : "/wdbcDataSet/wdbc.header",
	"headerDelimiter" : "|",
	"filterExpressions" : "",
	"weightColumnName" : "",
	"targetColumnName" : "diagnosis",
	"posTags" : [ "M" ],
	"negTags" : [ "B" ],
	"metaColumnNameFile" : "meta.column.names",
	"categoricalColumnNameFile" : "categorical.column.names"
  	},
</code></pre>

<p>Verify everything is set up correctly by running</p>

<pre><code>hadoopcli:wdbcModel$ shifu init
</code></pre>

<p>If successful, you should find <code>ColumnConfig.json</code> in your <code>wdbcModel</code> folder. Verify the content:</p>

<ul>
  <li>the first column should be <code>id</code> column and its flag is <code>Meta</code>
</li>
  <li>the second column should be <code>diagnosis</code> and its flag is <code>Target</code>
</li>
  <li>all the rest columns should have <code>columnType</code> as <code>N</code>, numerical</li>
  <li>all the columns should have <code>finalSelect</code> as <code>false</code> since this is just initialized</li>
  <li>all the columns should have <code>null</code> in <code>columnStats</code> and <code>columnBinning</code>
</li>
</ul>

<h2 id="calculate-statistics">Calculate Statistics</h2>

<p>Now we know the basics about the data set but nothing more than the names and their roles. By calculating the statistics of the columns, we can tell which columns are more valuable while which ones can be safely ignored without losing any information. The more data we have the more acurate the stats are, so only turn down the sampleRate if you hit the memory limit. Set the number of bins to a reasonable number and leave the <code>binningMethod</code> as <code>EB</code> for now so each bin will have equal number of positive records.</p>

<pre><code>"stats" : {
    "maxNumBin" : 10,
    "binningMethod" : "EqualPositive",
    "sampleRate" : 1.0,
    "sampleNegOnly" : false
},
</code></pre>

<p>Calculate stats:</p>

<pre><code>$ shifu stats
</code></pre>

<p>Open the <code>ColumnConfig</code> file, verify that all the columns except for <code>Meta</code> columns and <code>Target</code> column should have <code>columnStats</code> and <code>columnBinning</code> calculated. </p>

<p>Learn more from <a href="../../guide/columnconfig">ColumnConfig</a> and <a href="../../guide/stats">Pre-Train Stats</a> page.</p>

<h2 id="variable-selection">Variable Selection</h2>

<p>There are 3 methods for variable selection, in this tutorial we only use <code>Filter</code>, set <code>Force</code> and <code>Wrapper</code> to false; since we only have 30 column, you can set the <code>filterNum</code> to any number larger than 30 to use all of them, or a smaller number to actually do the variable selection, here we set it to 20; filtering by <code>KS</code> or <code>IV</code> should generate similar results. Here is a sample settings:</p>

<pre><code>"varSelect" : {
    "forceEnable" : false,
    ...
    "filterEnable" : true,
    "filterNum" : 20,
    "filterBy" : "KS",
    ...
},
</code></pre>

<p>Now kick off the job, this should be very fast since it only read ColumnConfig and edit <code>finalSelect</code> field and save it back. </p>

<pre><code>$ shifu varselect
</code></pre>

<p>You should see a list of selected variables. Check ColumnConfig to see if the <code>finalSelect</code> fields are correctly set.</p>

<p>Learn more from <a href="../../guide/varselect">Variable Selection</a> page.</p>

<h2 id="normalization">Normalization</h2>

<p>This is a small dataset so you might want to use all the data, so keep the sampleRate to 1.0. All the rest options can be safely keep as default.</p>

<pre><code>"normalize" : {
    "stdDevCutOff" : 4.0,
    "sampleRate" : 1.0,
    "sampleNegOnly" : false
},
</code></pre>

<p>Start normalization:</p>

<pre><code>$ shifu normalize
</code></pre>

<p>The normalized data will be saved under <code>tmp/NormalizedData</code></p>

<p>Learn more from <a href="../../guide/normalize">Normalization</a> page.</p>

<h2 id="train">Train</h2>

<p>Use the default settings to train a neural network</p>

<pre><code>$ shifu train
</code></pre>

<p>Check the <code>train</code> page for details.</p>

<p>Learn more from <a href="../../guide/train">Train</a> page.</p>

<h2 id="evaluation">Evaluation</h2>

<p><code>dataSet</code> has the same options as the one specifying the training data. The only difference is the dataPath: point it to <code>wdbc.eval</code> instead of <code>wdbc.train</code>.</p>

<p><code>dataSet#weightColumnName</code> is used to set the weight for each record when calculating performance matrix. If this is null, all the records will receive weight of 1.0, so the result for <code>Weighted</code> will be the same as <code>Unit</code>.</p>

<p>Run the evaluation</p>

<pre><code>$ shifu eval
</code></pre>


        </div>
      </div>

      <div class="col-md-3">
        <div id="side">
          <h1>Wisconsin Diagnostic Breast Cancer Tutorial</h1><ul class="toc"><li><a href="#prerequisites">Prerequisites</a></li><li><a href="#prepare-the-training-data">Prepare the training data</a></li><li><a href="#create-initial-modelconfig">Create Initial ModelConfig</a></li><li><a href="#choose-the-runmode">Choose the RunMode</a></li><li><a href="#create-initial-columnconfig">Create Initial ColumnConfig</a></li><li><a href="#calculate-statistics">Calculate Statistics</a></li><li><a href="#variable-selection">Variable Selection</a></li><li><a href="#normalization">Normalization</a></li><li><a href="#train">Train</a></li><li><a href="#evaluation">Evaluation</a></li></ul>
        </div>
      </div>
    </div>
  </div>
  
    </main>

  <div id="footer">
    <div class="container">
      <div class="row">
        <div id="footer-content">
          Lovingly crafted at <a href="https://www.paypal.com" alt="PayPal">PayPal</a>, code licensed under <a href="http://www.apache.org/licenses/LICENSE-2.0.html" alt="Apache License.">Apache License v2.0</a><br>
        </div>
      </div>
    </div>
  </div><!--footer-->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-47925727-1', 'auto');
  ga('send', 'pageview');

</script>

</body>
</html>

<!DOCTYPE HTML>

<html lang="en">
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="description" content="Shifu" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Wisconsin Diagnostic Breast Cancer Tutorial</title>
  <script src="http://code.jquery.com/jquery-latest.js" type="text/javascript">
</script>
  <link rel="stylesheet" href="//netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css" type="text/css">
  <script src="//netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js" type="text/javascript">
</script>
  <script src="/javascripts/main.js" type="text/javascript">
</script>
  <link rel="stylesheet" href="/coderay.css" type="text/css">
  <link rel="stylesheet" href="/style.css" type="text/css">
  <link rel="icon" href="/images/owl_head_32.png">
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>

  <body>
	
	<header id="header" role="banner">
		<nav class="navbar navbar-default" role="navigation">
			<div class="navbar-header">
			  <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar-collapse">
				<span class="sr-only">Toggle navigation</span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
			  </button>
			  <a href="http://paypal.github.io" class="navbar-brand"><img src="/images/OSSLogoPP.png" alt="PayPal open source" /></a>
			</div>
			<div class="collapse navbar-collapse" id="navbar-collapse">
				<ul class="nav navbar-nav">
					<li><a href="/" id="shifu-logo"><img src="/images/shifu-logo.png" height="44" ></a>



					<!--<li><a href="/project/about">About</a></li>-->

          <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown">Project<b class="caret"></b></a>
            <ul class="dropdown-menu">
              <li><a href="/project/about">About</a></li>
              <li><a href="/project/how-to-contribute">How to Contribute</a></li>
              
            </ul>
          </li>

					<li class="dropdown">
						<a href="#" class="dropdown-toggle" data-toggle="dropdown">Getting Started<b class="caret"></b></a>
						<ul class="dropdown-menu">
							<li><a href="/project/download">Download</a></li>
							<li><a href="/docs/shifu-core/0.2.x/tutorials/quickstart">Quick Start</a></li>

						</ul>
					</li>
					<li class="dropdown">
						<a href="#" class="dropdown-toggle" data-toggle="dropdown">Documentation<b class="caret"></b></a>
						<ul class="dropdown-menu">
							<li><a href="/docs/shifu-core/0.2.x">Shifu-Core</a></li>
							<li><a href="/docs/guagua">Guagua</a></li>
						</ul>
					</li>
					
				</ul>
			</div>
		</nav>
	</header>
 
  

  <div class="container" id="content">
    <div class="row">
      <div class="col-md-9">
        <div id="main">
          
<h1 id="wisconsin-diagnostic-breast-cancer-tutorial">Wisconsin Diagnostic Breast Cancer Tutorial</h1>

<h2 id="install-shifu">Install Shifu</h2>

<p>If you haven’t installed Shifu, please find the instructions on the <a href="/install">Install</a> page </p>

<h2 id="prepare-dataset">Prepare DataSet</h2>

<p>In this tutorial we are using the data titled Wisconsin Diagnostic Breast Cancer (WDBC)</p>

<p>Read about the dataset</p>

<pre><code>http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names
</code></pre>

<p>Create a new folder <code>wdbc</code> to store our data and models. Inside it, create <code>wdbcDataSet</code> folder:</p>

<pre><code>$ mkdir wdbcDataSet
$ cd wdbcDataSet
</code></pre>

<p>Download data:</p>

<pre><code>$ wget http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data
</code></pre>

<p>Split data into 2 parts: train and eval(modify <code>s</code> if desired):</p>

<pre><code>$ awk '{s=rand(); if(s&gt;0.8){print &gt; "wdbc.train"}else{print &gt; "wdbc.eval"}}' wdbc.data
</code></pre>

<p>Manually create a header file from <code>wdbc.names</code> section 7, save as <code>wdbc.header</code>:</p>

<pre><code>id|diagnosis|mean_radius|mean_texture|mean_perimeter|mean_area|mean_smoothness|mean_compactness|mean_concavity|mean_concave_points|mean_symmetry|mean_fractal_dimension|std_radius|std_texture|std_perimeter|std_area|std_smoothness|std_compactness|std_concavity|std_concave_points|std_symmetry|std_fractal_dimension|worst_radius|worst_texture|worst_perimeter|worst_area|worst_smoothness|worst_compactness|worst_concavity|worst_concave_points|worst_symmetry|worst_fractal_dimension
</code></pre>

<p>The folder layout should be:</p>

<pre><code>wdbc
└───wdbcDataSet/
    ├───wdbc.data
    ├───wdbc.train
    ├───wdbc.eval
    └───wdbc.header
</code></pre>

<p>Optional: put the wdbc folder onto HDFS if you would like to try it on cluster.</p>

<h2 id="create-initial-modelconfig">Create Initial ModelConfig</h2>

<p>Move out of the wdbcDataSet folder so we do not pollute it</p>

<pre><code>$ cd ..
</code></pre>

<p>Create a new ModelSet:</p>

<pre><code>$ shifu new wdbcModelSet
$ cd wdbcModelSet
</code></pre>

<p>A ModelConfig file has been created inside the wdbcModelSet folder.</p>

<pre><code>wdbc
├───wdbcDataSet/
│   ├───wdbc.data
│   ├───wdbc.train
│   ├───wdbc.eval
│   └───wdbc.header
└───wdbcModelSet/
    └───ModelConfig.json
</code></pre>

<h2 id="choose-mode">Choose Mode</h2>

<p>You can choose either <code>mapred</code> or <code>local</code> for executing the jobs.</p>

<ul>
  <li>
<code>mapred</code>: a set of MapReduce jobs will be generated and it is either run on a Hadoop cluster or on a single machine by pig’s <code>local</code> mode. However currently the training step is an exception, it will always run on local machine.</li>
  <li>
<code>local</code>: an alternative way for distributed computing, with no dependencies on Hadoop. </li>
</ul>

<h2 id="create-initial-columnconfig">Create Initial ColumnConfig</h2>

<p>Create a <code>meta.names</code> and put <code>id</code> in it, so <code>id</code> column is not treated as variable:</p>

<pre><code># meta.names
id
</code></pre>

<p>Edit ModelConfig file <code>dataSet</code> section.</p>

<p>Keep the source as <code>LOCAL</code> or change to <code>HDFS</code> if data is on hdfs</p>

<pre><code>"source" : "LOCAL",
</code></pre>

<p>Change <code>dataPath</code> and <code>dataDelimiter</code></p>

<pre><code>"dataPath" : "/path/to/wdbc.train",
"dataDelimiter" : ",",
</code></pre>

<blockquote>
  <p><strong>Note</strong></p>

  <p>Currently the <code>path</code> does not support <code>~</code>, use absolute path instead.</p>
</blockquote>

<p>Change <code>headerPath</code> and <code>headerDelimiter</code></p>

<pre><code>"headerPath" : "/path/to/wdbc.header",
"headerDelimiter" : "|",
</code></pre>

<p>Keep <code>filterExpressions</code> as null to use all the data</p>

<pre><code>"filterExpressions" : null,
</code></pre>

<p>Change <code>targetColumnName</code> to <code>diagnosis</code></p>

<pre><code>"targetColunmName" : "diagnosis",
</code></pre>

<p>There are two classes in <code>diagnosis</code>, let’s use <code>M</code> as positive tag and <code>B</code> as negative tag.</p>

<pre><code>"posTags" : [ "M" ],
"negTags" : [ "B" ],
</code></pre>

<p>Tell <code>Shifu</code> which columns are meta</p>

<pre><code>"metaColumnNameFile" : "meta.names",
</code></pre>

<p>And in our case there is no categorical data, so keep this as <code>null</code></p>

<pre><code>"categoricalColumnNameFile" : null
</code></pre>

<p>Done. Now create initial ColumnConfig by running:</p>

<pre><code>$ shifu init
</code></pre>

<p>You should find a <code>ColumnConfig.json</code> in your ModelSet folder. Verify the content:</p>

<ul>
  <li>the first column should be <code>id</code> column and its flag is <code>Meta</code>
</li>
  <li>the second column should be <code>diagnosis</code> and its flag is <code>Target</code>
</li>
  <li>all the rest columns should have <code>columnType</code> as <code>N</code>, numerical</li>
  <li>all the columns should have <code>finalSelect</code> as <code>false</code> since this is just initialized</li>
  <li>all the columns should have <code>null</code> in <code>columnStats</code> and <code>columnBinning</code>
</li>
</ul>

<h2 id="calculate-statistics">Calculate Statistics</h2>

<p>Now we know the basics about the data set but nothing more than the names and their roles. By calculating the statistics of the columns, we can tell which columns are more valuable while which ones can be safely ignored without losing any information. The more data we have the more acurate the stats are, so only turn down the sampleRate if you hit the memory limit. Set the number of bins to a reasonable number and leave the <code>binningMethod</code> as <code>EB</code> for now so each bin will have equal number of positive records.</p>

<pre><code>"stats" : {
    "maxNumBin" : 10,
    "binningMethod" : "EqualPositive",
    "sampleRate" : 1.0,
    "sampleNegOnly" : false
},
</code></pre>

<p>Calculate stats:</p>

<pre><code>$ shifu stats
</code></pre>

<p>Open the <code>ColumnConfig</code> file, verify that all the columns except for <code>Meta</code> columns and <code>Target</code> column should have <code>columnStats</code> and <code>columnBinning</code> calculated. </p>

<p>Learn more from <a href="/docs/columnconfig">ColumnConfig</a> and <a href="/docs/stats">Pre-Train Stats</a> page.</p>

<h2 id="variable-selection">Variable Selection</h2>

<p>There are 3 methods for variable selection, in this tutorial we only use <code>Filter</code>, set <code>Force</code> and <code>Wrapper</code> to false; since we only have 30 column, you can set the <code>filterNum</code> to any number larger than 30 to use all of them, or a smaller number to actually do the variable selection, here we set it to 20; filtering by <code>KS</code> or <code>IV</code> should generate similar results. Here is a sample settings:</p>

<pre><code>"varSelect" : {
    "forceEnable" : false,
    ...
    "filterEnable" : true,
    "filterNum" : 20,
    "filterBy" : "KS",
    ...
},
</code></pre>

<p>Now kick off the job, this should be very fast since it only read ColumnConfig and edit <code>finalSelect</code> field and save it back. </p>

<pre><code>$ shifu varselect
</code></pre>

<p>You should see a list of selected variables. Check ColumnConfig to see if the <code>finalSelect</code> fields are correctly set.</p>

<p>Learn more from <a href="/docs/varselect">Variable Selection</a> page.</p>

<h2 id="normalization">Normalization</h2>

<p>This is a small dataset so you might want to use all the data, so keep the sampleRate to 1.0. All the rest options can be safely keep as default.</p>

<pre><code>"normalize" : {
    "stdDevCutOff" : 4.0,
    "sampleRate" : 1.0,
    "sampleNegOnly" : false
},
</code></pre>

<p>Start normalization:</p>

<pre><code>$ shifu normalize
</code></pre>

<p>The normalized data will be saved under <code>tmp/NormalizedData</code></p>

<p>Learn more from <a href="/docs/normalize">Normalization</a> page.</p>

<h2 id="train">Train</h2>

<p>Use the default settings to train a neural network</p>

<pre><code>$ shifu train
</code></pre>

<p>Check the <code>train</code> page for details.</p>

<p>Learn more from <a href="/docs/train">Train</a> page.</p>

<h2 id="evaluation">Evaluation</h2>

<p><code>dataSet</code> has the same options as the one specifying the training data. The only difference is the dataPath: point it to <code>wdbc.eval</code> instead of <code>wdbc.train</code>.</p>

<p><code>dataSet#weightColumnName</code> is used to set the weight for each record when calculating performance matrix. If this is null, all the records will receive weight of 1.0, so the result for <code>Weighted</code> will be the same as <code>Unit</code>.</p>

<p>Run the evaluation</p>

<pre><code>$ shifu eval
</code></pre>

<p>The performance matrix will be printed out in terminal, to visualize the result, visit <a href="http://10.9.187.2:8080/performance">http://10.9.187.2:8080/performance</a> and upload the <code>EvalPerformance.json</code> file.</p>

        </div>
      </div>

      <div class="col-md-3">
        <div id="side">
          <h1>Wisconsin Diagnostic Breast Cancer Tutorial</h1><ul class="toc"><li><a href="#install-shifu">Install Shifu</a></li><li><a href="#prepare-dataset">Prepare DataSet</a></li><li><a href="#create-initial-modelconfig">Create Initial ModelConfig</a></li><li><a href="#choose-mode">Choose Mode</a></li><li><a href="#create-initial-columnconfig">Create Initial ColumnConfig</a></li><li><a href="#calculate-statistics">Calculate Statistics</a></li><li><a href="#variable-selection">Variable Selection</a></li><li><a href="#normalization">Normalization</a></li><li><a href="#train">Train</a></li><li><a href="#evaluation">Evaluation</a></li></ul>
        </div>
      </div>
    </div>
  </div>
  
    </main>

  <div id="footer">
    <div class="container">
      <div class="row">
        <div id="footer-content">
          Lovingly crafted at <a href="https://www.paypal.com" alt="PayPal">PayPal</a>, code licensed under <a href="http://www.apache.org/licenses/LICENSE-2.0.html" alt="Apache License.">Apache License v2.0</a><br>
        </div>
      </div>
    </div>
  </div><!--footer-->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-47925727-1', 'auto');
  ga('send', 'pageview');

</script>

</body>
</html>
